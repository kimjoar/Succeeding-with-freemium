\chapter{Methodology}
\label{chapter:methodology}

It is the problem statement that determines the methodology used \citep{berg2007}. The research in this paper is related to how and why companies have succeeded and failed using freemium. This is a wide problem statement, and this will have an impact on the methodology chosen, in the sense that it touches on choice of research strategy, choice of research design, on the specific methods for collecting data, and how the data is analyzed. This is what the following chapter considers.

% Löfgren (1996) claims that any research effort is framed by the world view of the researcher, meaning the researcher has some preconceived notions of how the world look, what concepts constitute the world, and what basic mechanisms affect these concepts. These are ontological considerations. These notions of how the world look and work are however not complete, and thus we need some idea of what can be regarded as acceptable knowledge and how it is required. These considerations are epistemological. It is this latter concept that helps us create the problem statement and the methodology that is used to answer the questions we ask about the world, both in the sense of the method for data collection as well as the method for analyzing and interpreting the data. Since epistemology is a general approach, any empirical work has to adapt the general epistemological rules and recommendations to the specific context or the research in question (Löfgren 1996). Following this, the chapter describes the various parts of the research and the rationality behind them.

\section{Choice of Research Strategy}

As the key theoretical themes of freemium are weakly developed, a more open-ended research strategy is employed --- a qualitative methodology. According to \citet{eisenhardt1989} a qualitative approach can make a significant contribution to theory development. \citet{berg2007} claims that the qualitative methodology is better than a quantitative methodology for going in depth to find the typical phenomenon that we wish to explore --- as \citet{bryman2008} states, it is about theory emerging from research, rather than the other way around.

\section{Choice of Research Design}

To answer the research question in this paper, a comparative case study methodology is used. Case studies often ask \q{how} and \q{why} questions \citep{tellis1997}, as this paper does. In addition the research question relates to both successes and failures, another reason why a comparison is apt. A comparative case study enable a detailed and intensive analysis of a set of cases, and facilitates theoretical reflections based on the distinguishing characteristics of these cases \citep{bryman2008}. As there have been little to no research specifically on freemium thus far, and as this paper is a prelude to a larger and more comprehensive investigation of freemium in an ensuing Master's Thesis, an exploratory approach is used.

\section{Choice of Research Method}

There are many possible sources of evidence in case studies, including documents, interviews, and participant-observation \citep{tellis1997}. For the purpose of answering the research question in this paper, an unobtrusive measure was chosen. For that reason this paper is based on the extensive public information sharing of companies that have used or is still using freemium.\footnote{Especially the second generation of web sites, often termed \term{Web 2.0}, has increased the information sharing of companies. This include company blogs, conferences, podcasts, sharing sites such as Twitter (\url{http://twitter.com}), discussion sites such as Hacker News (\url{http://news.ycombinator.com}), Q\&A sites such as Quora (\url{http://quora.com}), and many other places.} As such, the research method used in this paper is qualitative content analysis.

Content analysis is about interpreting meaning from the content of data, and the goal is \q{to provide knowledge and understanding of the phenomenon under study} \citep[\p{314}]{downe1992}. \citet[\p{18}]{krippendorff2004} defines it as \q{a research technique for making replicable and valid inferences from texts (or other meaningful matter) to the contexts of their use.} This paper entails a subjective interpretation of the information shared from the chosen companies.

\section{Sampling \oldand Case Selection}

The cases are not chosen randomly, they are sampled purposively to maximize the theoretical inferences that can be made from them \citep{eisenhardt1989,flyvbjerg2004}. The goal is not generalizability, but to get a deeper understanding of freemium.

% the aim is to make logical generalizations to a theoretical understanding of a similar class of phenomena rather than probabilistic generalizations to a population

\citet{bryman2008} distinguishes five types of cases: critical, extreme, typical, revelatory and longitudinal. To identify key success factors, we will look at extreme cases --- specifically those that have either succeeded or failed when using freemium. The reason for this is that these often reveal more information as they activate more basic mechanisms in the situation studied \citep{flyvbjerg2004}. 

The process for selecting cases comprises three steps. First of all a comprehensive collection of cases that have been or is still using freemium is assembled. These cases will be screened on whether or not they have extensively shared information about their use of freemium, which is subjectively measured from case to case as the information is inherently unstructured and in different channels. This process will primarily be performed using search engines such as Google and Bing, blog networks such as Techcrunch and ReadWriteWeb, and link sharing sites such as Reddit and Hacker News.\footnote{These can be accessed on \url{http://google.com}, \url{http://bing.com}, \url{http://techcrunch.com}, \url{http://readwriteweb.com}, \url{http://reddit.com}, and \url{http://news.ycombinator.com}, respectively.}

Secondly, the found cases are classified according to how relevant they are for the paper, \ie whether or not they are successful, how much information they have shared about using freemium, in which media they have shared information, and how credible the available information is. Judging their success or failure will be based on whether or not they have been able to create a viable business model. As stated in the introduction, success in this regards is defined as the company having been able to profitably use freemium. In many cases this is not evident, and these cases are less likely to be chosen, but they will not be set aside entirely. If they show signs of being successful or unsuccessful, which is subjectively measured, they are still selectable.

Thirdly, a subset of the cases, including both successful and unsuccessful, are chosen. The primary reason for examining both types, is that the non-successful companies may show some of the same characteristics as the successful ones \citep{fritz2004}. 

\section{Data Collection}

When the cases are chosen, data collection will begin. As data is already collected to choose cases, this entails a more thorough investigation into the chosen cases. This process will, as for finding cases, primarily be performed using search engines such as Google and Bing, blog networks such as Techcrunch and ReadWriteWeb, and link sharing sites such as Reddit and Hacker News.

Data will be accepted if it pertains to the chosen case and is shared either by a founder; someone at the \q{\abbr{CXO} level}, \eg the \abbr{CEO} or \abbr{COO}; an investor; or if it is public information from the company, \eg an annual report. Accepted sources are any than can be subjectively trusted, \ie secondhand information such as interviews by newspapers or other publications, but will focus on those that can be objectively trusted, \eg company blogs, video interviews, what these sources have written on their own blogs, and other similar sources. All types of sources are accepted, thus there are no limitations on it having to be written data.

The collection of data is performed over a short period of time, but there are no limitations as to when the data was published, though newer information is preferred.

\section{Data Analysis}

As said, this paper is based on a qualitative content analysis. Sources accepted are both textual and non-textual, and the latter will be partially transcribed. Further transcription is not deemed necessary, as the sources are publicly available. 

The analysis of data is performed in a way that is reminiscent of \term{grounded theory,} which is primarily concerned with development of theory out of data \citep{bryman2008}. Grounded theory should however be seen as an ideal rather than something that is possible, as \citet{bryman2008} states: \q{It is rarely accepted that theory-neutral observation is feasible.} 

From the transcriptions and textual sources, the units of data are categorized using inductive categories developed from the data themselves, which are compared to find consistencies and differences. Thus, this involve constant comparison between data and conceptualization.

\section{Reliability \oldand Validity}

Evaluation of qualitative data is not as well-defined as for quantitative data, where \term{reliability} and \term{validity} are used, as these two are viewed as positivistically oriented \citep{bryman2008}. In addition to these two concepts, \citet{bryman2008} presents two other stances for qualitative data, \term{trustworthiness} and \term{authenticity}. However, for the purpose of this paper the concepts of reliability and validity are used.

For reliability and validity in a qualitative context, \citet{bryman2008} suggests four concepts: \term{External reliability,} relating to the degree to which a study can be replicated; \term{internal reliability,} relating to inter-observer consistency; \term{internal validity,} meaning that there is a good match between the researchers’ observations and the theoretical ideas developed; and \term{external validity,} which relates to generalizability.

To increase the replicability of this paper, and thus the external reliability, the research process is thoroughly described. Adding to the replicability is the fact that the paper is based on publicly available information and is unobtrusively measured. As there are only one observer, there is no problem with regards to inter-observer consistency, and it can therefore be said to be a consistency in the research process.

To increase the internal validity of the paper \term{low inference descriptors}, \eg verbatim accounts of the gathered data, and \term{pattern matching}, \eg by examining multiple cases, are used \citep{johnson1997}. Additionally the analysis is only based on the \term{manifest content}, \ie those elements that are physically present, and is not based on an interpretive reading of underlying meanings. Other strategies for increasing the internal validity are \term{triangulation} and \term{respondent validation}, but these are seen as outside the scope of this paper because of time limitations.

This paper makes no try to generalize the findings to other contexts or settings. The focus is on understanding the area under investigation, freemium, in order to build a base for an ensuing Master's Thesis. The external validity is, however, increased by the reader having access to all the collected information to decide whether the findings might be transferable to other settings \citep{payne2005}.

\newthought{For assessing the quality of documents}, \citet{scott1990} and \citet{berg2007} each suggests four criteria, that can be summarized as follows:

\begin{enum}
  \iterm{Authenticity} Is the evidence genuine and of unquestionable origin, \eg whose Web site is it?
  \iterm{Credibility} Is the evidence free from error and distortion? Can it be corroborated?
  \iterm{Representativeness} Is the evidence typical of its kind? Is it current or dated?
  \iterm{Meaning} Is the evidence clean and comprehensible?
\end{enum}

The Internet has a huge potential as a source of documents, but at the same time it \q{contains a great deal of misleading and downright incorrect information} \citep{bryman2008}. Using these four criteria we can be more certain to the validity of the collected information, and they are therefore used when subjectively accepting or rejecting information. As the relevant discussion for these criteria can be seen from earlier discussions in this paper, they will not be further elaborated here.

% Se liste på \p{380}. Diskusjon i forhold til overview of criteria på \p{383}.
% 
% Tabell \p{393}.
% 
% We interview people to find out from them those things we cannot directly observe. The issue is not whether observational data are more desirable, valid or meaningful than self-report data. The fact is that we cannot observe everything. We cannot observe feelings, thoughts, and intentions. We cannot observe behaviours that took place at some previous point in time. We cannot observe situations that preclude the presence of an observer. We cannot observe how people have organized the world and the meanings they attach to what goes on in the world. We have to ask people questions about those things. 
% 
% The purpose of interviewing, then, is to allow us to enter into the other person's perspective. Qualitative interviewing begins with the assumption that the perspective of others is meaningful, knowable and able to be made explicit. We interview to find out what is in and on someone else's mind, to gather their stories (Patton 2002:341)
%
% The case study is also effective for generalizing using the type of test that Karl Popper called falsification, which forms part of critical reflexivity \citep{flyvbjerg2004}. Falsification is one of the most rigorous tests to which a scientific proposition can be subjected: if just one observation does not fit with the proposition it is considered not valid generally and must therefore be either revised or rejected.